{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b0f7215-c218-4e0e-baa4-537a299845ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.591207700Z",
     "start_time": "2024-10-22T18:32:24.201531Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer, load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iris"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6945c7ddb4c5d288"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.606208600Z",
     "start_time": "2024-10-22T18:32:24.587208200Z"
    }
   },
   "id": "6a1e271d249b2176"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement Naive Bayes classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb5e0db3187bc6b6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78bf2adf-3a98-4bf5-904c-781fc89677da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.623207600Z",
     "start_time": "2024-10-22T18:32:24.606208600Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyGaussianNB:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_labels, self.class_counts = np.unique(y, return_counts=True)\n",
    "        self.class_priors = np.log(self.class_counts / self.class_counts.sum())\n",
    "\n",
    "        class_means = []\n",
    "        class_variance = []\n",
    "        for label in self.class_labels:\n",
    "            current_X = X[np.where(y == label)]\n",
    "            mean = np.mean(current_X, axis=0)\n",
    "            double_variance = np.var(current_X, axis=0)\n",
    "            class_means.append(mean)\n",
    "            class_variance.append(double_variance)\n",
    "\n",
    "        self.class_means = np.array(class_means)\n",
    "        self.class_variance = 2 * np.array(class_variance)\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # for proper broadcasting and optimal numpy we need to extend dimensions\n",
    "        means = self.class_means[None, :, :]\n",
    "        variances = self.class_variance[None, :, :]\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            # suppress 0 division warnings I guess\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            norms = np.log(\n",
    "                np.exp(-np.square(X[:, None, :] - means) / (variances))\n",
    "                / np.sqrt(np.pi * variances)\n",
    "            )\n",
    "\n",
    "        # norms are a vector of (60,3,4 values) - log_probabilities for each dimension, for each class, fore each X\n",
    "        probas = norms.sum(axis=-1) + self.class_priors\n",
    "\n",
    "        # at this point probas is a (X.shape[0],n_classes) vector of summed log proba values for each class\n",
    "        return self.class_labels[probas.argmax(axis=-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check the results of naive bayes classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a35f9529933c5d97"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c5b3a9-7fd1-41d9-8ad9-1e23ac9341a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.681208600Z",
     "start_time": "2024-10-22T18:32:24.623207600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my acc       : 0.96\n",
      "my f1        : [1.         0.94014963 0.93984962]\n",
      "my prec      : [1.     0.9425 0.9375]\n",
      "\n",
      "sklearn acc  : 0.96\n",
      "sklearn f1   : [1.         0.94014963 0.93984962]\n",
      "sklearn prec : [1.     0.9425 0.9375]\n",
      "\n",
      "Results of custom and library classifiers match in 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "\n",
    "\n",
    "my_pred = []\n",
    "sklearn_pred = []\n",
    "actual_labels = []\n",
    "\n",
    "for i in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris[\"data\"],\n",
    "        iris[\"target\"],\n",
    "        train_size=0.6,\n",
    "        stratify=iris[\"target\"],\n",
    "        random_state=i,\n",
    "    )\n",
    "\n",
    "    actual_labels.append(y_test)\n",
    "\n",
    "    clf_mine = MyGaussianNB()\n",
    "    clf_mine.fit(X_train, y_train)\n",
    "    my_pred.append(clf_mine.predict(X_test))\n",
    "\n",
    "    clf_sklearn = GaussianNB()\n",
    "    clf_sklearn.fit(X_train, y_train)\n",
    "\n",
    "    sklearn_pred.append(clf_sklearn.predict(X_test))\n",
    "\n",
    "my_pred = np.concatenate(my_pred)\n",
    "sklearn_pred = np.concatenate(sklearn_pred)\n",
    "actual_labels = np.concatenate(actual_labels)\n",
    "\n",
    "print(f\"my acc       : {accuracy_score(my_pred,actual_labels)}\")\n",
    "print(f\"my f1        : {f1_score(my_pred,actual_labels,average=None)}\")\n",
    "print(f\"my prec      : {precision_score(my_pred,actual_labels,average=None)}\")\n",
    "print()\n",
    "print(f\"sklearn acc  : {accuracy_score(sklearn_pred,actual_labels)}\")\n",
    "print(f\"sklearn f1   : {f1_score(sklearn_pred,actual_labels,average=None)}\")\n",
    "print(f\"sklearn prec : {precision_score(sklearn_pred,actual_labels,average=None)}\")\n",
    "print()\n",
    "score_match = (my_pred == sklearn_pred).mean() * 100\n",
    "print(f\"Results of custom and library classifiers match in {score_match}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The scores returned by my classifier are identical to those returned by scikit-learn GaussianNB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4ace40d9167940c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Breast Cancer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "563a2dbd57d6f9d9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.712214300Z",
     "start_time": "2024-10-22T18:32:24.683208300Z"
    }
   },
   "id": "e5b607a48891f9f1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    breast_cancer[\"data\"], breast_cancer[\"target\"],\n",
    "    train_size=0.7,\n",
    "    stratify=breast_cancer[\"target\"],\n",
    "    random_state=42,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.719207600Z",
     "start_time": "2024-10-22T18:32:24.698208100Z"
    }
   },
   "id": "e23667da430fb8d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standardization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce9110ed725846da"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc  : 0.935672514619883\n",
      "f1   : 0.9493087557603687\n",
      "prec : 0.9626168224299065\n"
     ]
    }
   ],
   "source": [
    "clf = MyGaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"acc  : {accuracy_score(y_pred,y_test)}\")\n",
    "print(f\"f1   : {f1_score(y_pred,y_test)}\")\n",
    "print(f\"prec : {precision_score(y_pred,y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.729208100Z",
     "start_time": "2024-10-22T18:32:24.714208600Z"
    }
   },
   "id": "d70367887517130"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc  : 0.935672514619883\n",
      "f1   : 0.9493087557603687\n",
      "prec : 0.9626168224299065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = Pipeline([(\"scaler\",StandardScaler()),(\"nb\",MyGaussianNB())])\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"acc  : {accuracy_score(y_pred,y_test)}\")\n",
    "print(f\"f1   : {f1_score(y_pred,y_test)}\")\n",
    "print(f\"prec : {precision_score(y_pred,y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.776217200Z",
     "start_time": "2024-10-22T18:32:24.730207500Z"
    }
   },
   "id": "cb485baed3c76d45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's a well known fact that naive bayes is not impacted by scaling as the features create independent distributions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2913341dd3b6f1a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PCA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3820b124a991bd1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "clf = MyGaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "f1 = f1_score(y_pred,y_test)\n",
    "precision = precision_score(y_pred,y_test)\n",
    "\n",
    "best_accuracy = \"baseline\"\n",
    "best_f1 = \"baseline\"\n",
    "best_precision = \"baseline\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.782207800Z",
     "start_time": "2024-10-22T18:32:24.746207800Z"
    }
   },
   "id": "88fe6a4f2883f353"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid for best accuracy  (0.935672514619883) : \n",
      " {'pca__n_components': 5}\n",
      "grid for best f1        (0.9502262443438914) : \n",
      " {'pca__n_components': 5}\n",
      "grid for best precision (0.9813084112149533) : \n",
      " {'pca__n_components': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# PCA requires standardization\n",
    "clf = Pipeline([(\"scaler\",StandardScaler()),(\"pca\",PCA()),(\"nb\",MyGaussianNB())])\n",
    "\n",
    "param_grid = {\n",
    "    \"pca__n_components\":[25,20,15,10,5],\n",
    "}\n",
    "\n",
    "for grid in ParameterGrid(param_grid):\n",
    "    clf.set_params(**grid)\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy_ = accuracy_score(y_pred,y_test)\n",
    "    f1_ = f1_score(y_pred,y_test)\n",
    "    precision_ = precision_score(y_pred,y_test)\n",
    "    \n",
    "    if accuracy_ >= accuracy:\n",
    "        best_accuracy = grid\n",
    "        accuracy = accuracy_\n",
    "    \n",
    "    if f1_ >= f1:\n",
    "        best_f1 = grid\n",
    "        f1 = f1_\n",
    "    \n",
    "    if precision_ >= precision:\n",
    "        best_precision = grid\n",
    "        precision = precision_\n",
    "\n",
    "print(f\"grid for best accuracy  ({accuracy}) : \\n {best_accuracy}\")\n",
    "print(f\"grid for best f1        ({f1}) : \\n {best_f1}\")\n",
    "print(f\"grid for best precision ({precision}) : \\n {best_precision}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.840207500Z",
     "start_time": "2024-10-22T18:32:24.763207400Z"
    }
   },
   "id": "59658de2671d8618"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kernel PCA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dd543e60c116288"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "clf = MyGaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "f1 = f1_score(y_pred,y_test)\n",
    "precision = precision_score(y_pred,y_test)\n",
    "\n",
    "best_accuracy = \"baseline\"\n",
    "best_f1 = \"baseline\"\n",
    "best_precision = \"baseline\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:24.846208Z",
     "start_time": "2024-10-22T18:32:24.810207300Z"
    }
   },
   "id": "c3f2996418261e04"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid for best accuracy  (0.9473684210526315) : \n",
      " {'pca__kernel': 'cosine', 'pca__n_components': 10}\n",
      "grid for best f1        (0.958904109589041) : \n",
      " {'pca__kernel': 'cosine', 'pca__n_components': 10}\n",
      "grid for best precision (0.9813084112149533) : \n",
      " {'pca__kernel': 'cosine', 'pca__n_components': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# PCA requires standardization\n",
    "clf = Pipeline([(\"scaler\",StandardScaler()),(\"pca\",KernelPCA()),(\"nb\",MyGaussianNB())])\n",
    "\n",
    "param_grid = {\n",
    "    \"pca__n_components\":[25,20,15,10,5],\n",
    "    \"pca__kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"cosine\"]\n",
    "}\n",
    "\n",
    "for grid in ParameterGrid(param_grid):\n",
    "    clf.set_params(**grid)\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy_ = accuracy_score(y_pred,y_test)\n",
    "    f1_ = f1_score(y_pred,y_test)\n",
    "    precision_ = precision_score(y_pred,y_test)\n",
    "    \n",
    "    if accuracy_ >= accuracy:\n",
    "        best_accuracy = grid\n",
    "        accuracy = accuracy_\n",
    "    \n",
    "    if f1_ >= f1:\n",
    "        best_f1 = grid\n",
    "        f1 = f1_\n",
    "    \n",
    "    if precision_ >= precision:\n",
    "        best_precision = grid\n",
    "        precision = precision_\n",
    "\n",
    "print(f\"grid for best accuracy  ({accuracy}) : \\n {best_accuracy}\")\n",
    "print(f\"grid for best f1        ({f1}) : \\n {best_f1}\")\n",
    "print(f\"grid for best precision ({precision}) : \\n {best_precision}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:32:25.777835Z",
     "start_time": "2024-10-22T18:32:24.828207600Z"
    }
   },
   "id": "65421b13e6b4bf36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We managed to significantly improve the scores using Kernel PCA with cosine kernel and 10 components"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fefee3cd714810c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Box-Cox"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60c98343f2269ed4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# TODO BOX-COX"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T19:03:13.501655300Z",
     "start_time": "2024-10-22T19:03:13.479439Z"
    }
   },
   "id": "b21416ae4abbc63d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = MyGaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "f1 = f1_score(y_pred,y_test)\n",
    "precision = precision_score(y_pred,y_test)\n",
    "\n",
    "best_accuracy = \"baseline\"\n",
    "best_f1 = \"baseline\"\n",
    "best_precision = \"baseline\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2309f2c6511386c4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PowerTransformer\n",
    "# \n",
    "# clf = Pipeline([(\"boxcox\",PowerTransformer(method=\"box-cox\", standardize=False,alpha)),(\"nb\",MyGaussianNB())])\n",
    "# \n",
    "# for lambda_param in [[0.0], [0.1], [0.2], [0.3], [0.4], [0.5], [0.6], [0.7], [0.8], [0.9], [1.0]]:\n",
    "#     clf[\"boxcox\"].lambdas_ = lambda_param\n",
    "# \n",
    "#     clf.fit(X_train,y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     \n",
    "#     accuracy_ = accuracy_score(y_pred,y_test)\n",
    "#     f1_ = f1_score(y_pred,y_test)\n",
    "#     precision_ = precision_score(y_pred,y_test)\n",
    "#     \n",
    "#     if accuracy_ >= accuracy:\n",
    "#         best_accuracy = grid\n",
    "#         accuracy = accuracy_\n",
    "#     \n",
    "#     if f1_ >= f1:\n",
    "#         best_f1 = grid\n",
    "#         f1 = f1_\n",
    "#     \n",
    "#     if precision_ >= precision:\n",
    "#         best_precision = grid\n",
    "#         precision = precision_\n",
    "# \n",
    "# print(f\"grid for best accuracy  ({accuracy}) : \\n {best_accuracy}\")\n",
    "# print(f\"grid for best f1        ({f1}) : \\n {best_f1}\")\n",
    "# print(f\"grid for best precision ({precision}) : \\n {best_precision}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:49:34.561439500Z",
     "start_time": "2024-10-22T18:49:34.543438900Z"
    }
   },
   "id": "7deabc6b090db5a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Binomial Distribution NB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a23e598c9d96f0d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class MyBinomialNB:\n",
    "    def __init__(self,alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_labels, self.class_counts = np.unique(y, return_counts=True)\n",
    "        self.class_priors = np.log(self.class_counts / self.class_counts.sum())\n",
    "\n",
    "        class_probs = []\n",
    "        for label in self.class_labels:\n",
    "            current_X = X[np.where(y == label)]\n",
    "            \n",
    "            # laplace smoothing (x.sum()+1)/(|x|+2) instead of x.sum()/|x|\n",
    "            theta = (np.sum(current_X, axis=0) + self.alpha) / (current_X.shape[0] + self.alpha*2) \n",
    "            class_probs.append(theta)\n",
    "            \n",
    "            class_probs.append(np.mean(current_X, axis=0))\n",
    "\n",
    "        # Thetas\n",
    "        self.class_probs = np.array(class_probs)\n",
    "\n",
    "    def predict(self, X):    \n",
    "        log_prob_1 = np.log(self.class_probs)[None, :, :]\n",
    "        log_prob_0 = np.log(1 - self.class_probs)[None, :, :]\n",
    "        \n",
    "        likelihoods = (X[:, None, :] * log_prob_1 + (1 - X)[:, None, :] * log_prob_0).sum(axis=-1)\n",
    "        \n",
    "        probas = likelihoods + self.class_priors\n",
    "\n",
    "        # Return the class with the highest probability for each sample\n",
    "        return self.class_labels[probas.argmax(axis=-1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T19:10:19.029417800Z",
     "start_time": "2024-10-22T19:10:18.999411500Z"
    }
   },
   "id": "27dcd6df2a4f1e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "BernoulliNB()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d53f5541334e22e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
