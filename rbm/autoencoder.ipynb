{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Autoencoders\n",
    "\n",
    "## Data\n",
    "\n",
    "### Import and load datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "893e85ce239811db"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, KMNIST\n",
    "\n",
    "mnist = MNIST(\n",
    "    root=\"data/mnist\",\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "mnist_test = MNIST(root=\"data/mnist\", download=True, train=False)\n",
    "\n",
    "fashion = FashionMNIST(\n",
    "    root=\"data/fmnist\",\n",
    "    download=True,\n",
    ")\n",
    "fashion_test = FashionMNIST(root=\"data/fmnist\", download=True, train=False)\n",
    "\n",
    "kuzushiji = KMNIST(\n",
    "    root=\"data/kmnist\",\n",
    "    download=True,\n",
    ")\n",
    "kuzushiji_test = KMNIST(root=\"data/kmnist\", download=True, train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:24.486179200Z",
     "start_time": "2024-12-19T20:41:22.238291500Z"
    }
   },
   "id": "6146b6b353a14671"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "mnist_train_data = mnist.data\n",
    "mnist_train_labels = mnist.targets.numpy()\n",
    "mnist_test_data = mnist_test.data\n",
    "mnist_test_labels = mnist_test.targets.numpy()\n",
    "\n",
    "fashion_train_data = fashion.data\n",
    "fashion_train_labels = fashion.targets.numpy()\n",
    "fashion_test_data = fashion_test.data\n",
    "fashion_test_labels = fashion_test.targets.numpy()\n",
    "\n",
    "kuzushiji_train_data = kuzushiji.data\n",
    "kuzushiji_train_labels = kuzushiji.targets.numpy()\n",
    "kuzushiji_test_data = kuzushiji_test.data\n",
    "kuzushiji_test_labels = kuzushiji_test.targets.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:24.499013500Z",
     "start_time": "2024-12-19T20:41:24.488502800Z"
    }
   },
   "id": "9293b0e6bb8c1092"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalize the image histogram"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "600267ddad7cca1e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(images):\n",
    "    histograms = np.apply_along_axis(\n",
    "        np.bincount, 1, images.reshape(images.shape[0], -1), minlength=256\n",
    "    )\n",
    "\n",
    "    cdf = histograms.cumsum(axis=1)\n",
    "    cdf_min = cdf[:, 0][\n",
    "        :, None\n",
    "    ]  # Minimum of the CDF (first non-zero element in each row)\n",
    "\n",
    "    # Normalize the CDF for each image\n",
    "    cdf_m = ((cdf - cdf_min) * 255) / (cdf.max(axis=1)[:, None] - cdf_min)\n",
    "\n",
    "    cdf_m = cdf_m.astype(np.uint8)\n",
    "\n",
    "    # Apply normalized CDF to each image\n",
    "    normalized_images = cdf_m[\n",
    "        np.arange(images.shape[0])[:, None, None], images\n",
    "    ]  #  Broadcasting across images and index\n",
    "\n",
    "    return normalized_images\n",
    "\n",
    "\n",
    "mnist_train_data = normalize(mnist_train_data) / 265\n",
    "mnist_test_data = normalize(mnist_test_data) / 265\n",
    "\n",
    "fashion_train_data = normalize(fashion_train_data) / 265\n",
    "fashion_test_data = normalize(fashion_test_data) / 265\n",
    "\n",
    "kuzushiji_train_data = normalize(kuzushiji_train_data) / 265\n",
    "kuzushiji_test_data = normalize(kuzushiji_test_data) / 265"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:26.335718500Z",
     "start_time": "2024-12-19T20:41:24.492014200Z"
    }
   },
   "id": "ac7dab5168ba71c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert to torch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e10321a0f458775"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "mnist_train_data = torch.tensor(mnist_train_data, dtype=torch.float32)\n",
    "mnist_test_data = torch.tensor(mnist_test_data, dtype=torch.float32)\n",
    "\n",
    "fashion_train_data = torch.tensor(fashion_train_data, dtype=torch.float32)\n",
    "fashion_test_data = torch.tensor(fashion_test_data, dtype=torch.float32)\n",
    "\n",
    "kuzushiji_train_data = torch.tensor(kuzushiji_train_data, dtype=torch.float32)\n",
    "kuzushiji_test_data = torch.tensor(kuzushiji_test_data, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:26.455635100Z",
     "start_time": "2024-12-19T20:41:26.349718100Z"
    }
   },
   "id": "bfb8f4bd92b23256"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Model\n",
    "\n",
    "### Architecture"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a67a04f36fab956b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Define the autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, embedding_dim=196):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:26.471967200Z",
     "start_time": "2024-12-19T20:41:26.457831200Z"
    }
   },
   "id": "97dbd5ec53e15c57"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Define the autoencoder class\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=196):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, embedding_dim),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 32 * 7 * 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (32, 7, 7)),\n",
    "            nn.ConvTranspose2d(\n",
    "                32, 16, kernel_size=3, stride=2, padding=1, output_padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                16, 1, kernel_size=3, stride=2, padding=1, output_padding=1\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:26.471967200Z",
     "start_time": "2024-12-19T20:41:26.461705900Z"
    }
   },
   "id": "53c0587dd0f98494"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5687fcb73c457f6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "embedding_dim = 196\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning_rate = 1e-3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:26.471967200Z",
     "start_time": "2024-12-19T20:41:26.464443600Z"
    }
   },
   "id": "82ce61f4872a9332"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b382465f8a35f0c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:26.512860500Z",
     "start_time": "2024-12-19T20:41:26.494714700Z"
    }
   },
   "id": "7cb5f1d4f309205"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loop function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe19b5bdf3a10715"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    model, optimizer, train_dataset, test_dataset, dataset_name, flatten=True\n",
    "):\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            images = batch[0].squeeze()\n",
    "            if flatten:\n",
    "                images = images.view(-1, 784)\n",
    "            else:\n",
    "                images = images[:, None, :, :]\n",
    "            images = images.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_dataset)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                images = batch[0].squeeze()\n",
    "                if flatten:\n",
    "                    images = images.view(-1, 784)\n",
    "                else:\n",
    "                    images = images[:, None, :, :]\n",
    "                images = images.to(DEVICE)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, images)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(test_dataset)\n",
    "\n",
    "        if epoch % 5 == 4:\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\"\n",
    "            )\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), f\"autoencoder_{dataset_name}.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:26.512860500Z",
     "start_time": "2024-12-19T20:41:26.496231800Z"
    }
   },
   "id": "284a91744978fc82"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Score metrics for a model - "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "515f6e46fd876e10"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def get_score_df(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    result_df = pd.DataFrame(columns=[\"label\", \"auroc\", \"f1\", \"prec\", \"rec\"])\n",
    "    classes = np.unique(y_test)  # Assuming y_train contains all classes\n",
    "    for cls in classes:\n",
    "        binary_y_test = (y_test == cls).astype(int)\n",
    "        binary_y_pred = (y_pred == cls).astype(int)\n",
    "\n",
    "        auroc = roc_auc_score(binary_y_test, y_prob[:, cls])\n",
    "        f1 = f1_score(binary_y_test, binary_y_pred)\n",
    "        precision = precision_score(binary_y_test, binary_y_pred)\n",
    "        recall = recall_score(binary_y_test, binary_y_pred)\n",
    "\n",
    "        result_df.loc[result_df.shape[0]] = [cls, auroc, f1, precision, recall]\n",
    "\n",
    "    auroc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    result_df.loc[result_df.shape[0]] = [\"all\", auroc, f1, precision, recall]\n",
    "\n",
    "    return result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:27.046909400Z",
     "start_time": "2024-12-19T20:41:26.502864500Z"
    }
   },
   "id": "4cb574f490ad6156"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Train mnist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84969a5bcee9e38d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset_name = \"mnist\"\n",
    "\n",
    "train_data = mnist_train_data\n",
    "test_data = mnist_test_data\n",
    "\n",
    "train_labels = mnist_train_labels\n",
    "test_labels = mnist_test_labels\n",
    "\n",
    "train_dataset = TensorDataset(train_data)\n",
    "test_dataset = TensorDataset(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:41:27.062641100Z",
     "start_time": "2024-12-19T20:41:27.046909400Z"
    }
   },
   "id": "31d6bf456734134b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP AE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0d633b472a4d2f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.001631, Test Loss: 0.001631\n",
      "Epoch 10/50, Train Loss: 0.001557, Test Loss: 0.001568\n",
      "Epoch 15/50, Train Loss: 0.001524, Test Loss: 0.001545\n",
      "Epoch 20/50, Train Loss: 0.001503, Test Loss: 0.001520\n",
      "Epoch 25/50, Train Loss: 0.001487, Test Loss: 0.001504\n",
      "Epoch 30/50, Train Loss: 0.001475, Test Loss: 0.001492\n",
      "Epoch 35/50, Train Loss: 0.001464, Test Loss: 0.001485\n",
      "Epoch 40/50, Train Loss: 0.001455, Test Loss: 0.001472\n",
      "Epoch 45/50, Train Loss: 0.001448, Test Loss: 0.001465\n",
      "Epoch 50/50, Train Loss: 0.001441, Test Loss: 0.001457\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = Autoencoder(input_dim=input_dim, embedding_dim=embedding_dim).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(model, optimizer, train_dataset, test_dataset, dataset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:42:57.031353300Z",
     "start_time": "2024-12-19T20:41:27.050641500Z"
    }
   },
   "id": "a288bfebde453713"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "encodings_train = model.encoder(train_data.view(-1, 784).to(DEVICE))\n",
    "encodings_test = model.encoder(test_data.view(-1, 784).to(DEVICE))\n",
    "\n",
    "encodings_train = encodings_train.cpu().detach().numpy()\n",
    "encodings_test = encodings_test.cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:42:57.106010100Z",
     "start_time": "2024-12-19T20:42:57.032600500Z"
    }
   },
   "id": "3f249120b6addde9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c5273e25f028050"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc       f1      prec     rec\n10   all  0.996338  0.93452  0.934535  0.9346",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.996338</td>\n      <td>0.93452</td>\n      <td>0.934535</td>\n      <td>0.9346</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:43:02.266988400Z",
     "start_time": "2024-12-19T20:42:57.108010700Z"
    }
   },
   "id": "5906f9ea7a5e9535"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad2f39801835aaa"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc        f1      prec     rec\n10   all  0.997693  0.953408  0.953475  0.9535",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.997693</td>\n      <td>0.953408</td>\n      <td>0.953475</td>\n      <td>0.9535</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:43:08.379198800Z",
     "start_time": "2024-12-19T20:43:02.267989Z"
    }
   },
   "id": "ab3b4192ea6f29b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using Random Forest Classifier allowed us to improve the results slightly"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdd8bc8fbd592702"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convolution AE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfa47cbc72a03573"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.001443, Test Loss: 0.001443\n",
      "Epoch 10/50, Train Loss: 0.001408, Test Loss: 0.001414\n",
      "Epoch 15/50, Train Loss: 0.001394, Test Loss: 0.001401\n",
      "Epoch 20/50, Train Loss: 0.001384, Test Loss: 0.001394\n",
      "Epoch 25/50, Train Loss: 0.001378, Test Loss: 0.001385\n",
      "Epoch 30/50, Train Loss: 0.001373, Test Loss: 0.001380\n",
      "Epoch 35/50, Train Loss: 0.001370, Test Loss: 0.001377\n",
      "Epoch 40/50, Train Loss: 0.001367, Test Loss: 0.001376\n",
      "Epoch 45/50, Train Loss: 0.001365, Test Loss: 0.001374\n",
      "Epoch 50/50, Train Loss: 0.001364, Test Loss: 0.001373\n"
     ]
    }
   ],
   "source": [
    "model_conv = ConvAutoencoder(embedding_dim=embedding_dim).to(DEVICE)\n",
    "optimizer = optim.Adam(model_conv.parameters(), lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    model_conv, optimizer, train_dataset, test_dataset, dataset_name, flatten=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:44:24.759960300Z",
     "start_time": "2024-12-19T20:43:08.379198800Z"
    }
   },
   "id": "bcf575461da628fe"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model_conv.eval()\n",
    "\n",
    "encodings_train = model_conv.encoder(train_data[:, None, :, :].to(DEVICE))\n",
    "encodings_test = model_conv.encoder(test_data[:, None, :, :].to(DEVICE))\n",
    "\n",
    "encodings_train = encodings_train.cpu().detach().numpy()\n",
    "encodings_test = encodings_test.cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:44:24.861667700Z",
     "start_time": "2024-12-19T20:44:24.760959300Z"
    }
   },
   "id": "8a47161d948b793e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc       f1     prec     rec\n10   all  0.994577  0.92533  0.92537  0.9255",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.994577</td>\n      <td>0.92533</td>\n      <td>0.92537</td>\n      <td>0.9255</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:44:29.938699500Z",
     "start_time": "2024-12-19T20:44:24.862668200Z"
    }
   },
   "id": "c2e7adfd7a202cde"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   label    auroc        f1     prec     rec\n10   all  0.99762  0.950748  0.95084  0.9508",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.99762</td>\n      <td>0.950748</td>\n      <td>0.95084</td>\n      <td>0.9508</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:44:36.265640800Z",
     "start_time": "2024-12-19T20:44:29.925885800Z"
    }
   },
   "id": "7af9a965401ab2d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using embeddings made with convolution model yielded better value for reconstruction loss but the classification results were slightly worse.\n",
    "\n",
    "We still maintain better scores for random forest.\n",
    "\n",
    "\n",
    "Best results for mnist were achieved for the RBM used as the first layer of DBN training in the previous part of laboratory = above 0.998 auroc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff25871cdb3c9571"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Fashion mnist\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4edb6ee7ebc3b3d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dataset_name = \"fashion_mnist\"\n",
    "\n",
    "train_data = fashion_train_data\n",
    "test_data = fashion_test_data\n",
    "\n",
    "train_labels = fashion_train_labels\n",
    "test_labels = fashion_test_labels\n",
    "\n",
    "train_dataset = TensorDataset(train_data)\n",
    "test_dataset = TensorDataset(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:44:36.279668700Z",
     "start_time": "2024-12-19T20:44:36.265640800Z"
    }
   },
   "id": "41a18fab4300bdf5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP AE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70c38475d497578f"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.004730, Test Loss: 0.004756\n",
      "Epoch 10/50, Train Loss: 0.004591, Test Loss: 0.004634\n",
      "Epoch 15/50, Train Loss: 0.004513, Test Loss: 0.004557\n",
      "Epoch 20/50, Train Loss: 0.004460, Test Loss: 0.004513\n",
      "Epoch 25/50, Train Loss: 0.004424, Test Loss: 0.004474\n",
      "Epoch 30/50, Train Loss: 0.004399, Test Loss: 0.004454\n",
      "Epoch 35/50, Train Loss: 0.004380, Test Loss: 0.004435\n",
      "Epoch 40/50, Train Loss: 0.004366, Test Loss: 0.004424\n",
      "Epoch 45/50, Train Loss: 0.004355, Test Loss: 0.004411\n",
      "Epoch 50/50, Train Loss: 0.004346, Test Loss: 0.004404\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(input_dim=input_dim, embedding_dim=embedding_dim).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(model, optimizer, train_dataset, test_dataset, dataset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:45:41.942107200Z",
     "start_time": "2024-12-19T20:44:36.268672300Z"
    }
   },
   "id": "662f901a11407a0d"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "encodings_train = model.encoder(train_data.view(-1, 784).to(DEVICE))\n",
    "encodings_test = model.encoder(test_data.view(-1, 784).to(DEVICE))\n",
    "\n",
    "encodings_train = encodings_train.cpu().detach().numpy()\n",
    "encodings_test = encodings_test.cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:45:41.999211300Z",
     "start_time": "2024-12-19T20:45:41.943108700Z"
    }
   },
   "id": "1d244dc675b158a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13a89a4d40e469c2"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc        f1      prec     rec\n10   all  0.986044  0.855532  0.855222  0.8569",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.986044</td>\n      <td>0.855532</td>\n      <td>0.855222</td>\n      <td>0.8569</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:45:46.897355500Z",
     "start_time": "2024-12-19T20:45:42.006211900Z"
    }
   },
   "id": "c471fd0947e778ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32beb44eaf8815c2"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc        f1      prec     rec\n10   all  0.985463  0.845515  0.846765  0.8484",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.985463</td>\n      <td>0.845515</td>\n      <td>0.846765</td>\n      <td>0.8484</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:45:53.135743800Z",
     "start_time": "2024-12-19T20:45:46.897355500Z"
    }
   },
   "id": "cb9324120bdd7c74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In case of fashion mnist, using random forest didn't improve the classification result for mlp-based autoencoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15dc59f23b95dd8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convolution AE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4eeebb426aadf813"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.004402, Test Loss: 0.004432\n",
      "Epoch 10/50, Train Loss: 0.004323, Test Loss: 0.004360\n",
      "Epoch 15/50, Train Loss: 0.004303, Test Loss: 0.004343\n",
      "Epoch 20/50, Train Loss: 0.004291, Test Loss: 0.004333\n",
      "Epoch 25/50, Train Loss: 0.004285, Test Loss: 0.004328\n",
      "Epoch 30/50, Train Loss: 0.004280, Test Loss: 0.004324\n",
      "Epoch 35/50, Train Loss: 0.004277, Test Loss: 0.004320\n",
      "Epoch 40/50, Train Loss: 0.004274, Test Loss: 0.004318\n",
      "Epoch 45/50, Train Loss: 0.004271, Test Loss: 0.004315\n",
      "Epoch 50/50, Train Loss: 0.004269, Test Loss: 0.004315\n"
     ]
    }
   ],
   "source": [
    "model_conv = ConvAutoencoder(embedding_dim=embedding_dim).to(DEVICE)\n",
    "optimizer = optim.Adam(model_conv.parameters(), lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    model_conv, optimizer, train_dataset, test_dataset, dataset_name, flatten=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:47:05.805523900Z",
     "start_time": "2024-12-19T20:45:53.136745800Z"
    }
   },
   "id": "34524aa862455c28"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "model_conv.eval()\n",
    "\n",
    "encodings_train = model_conv.encoder(train_data[:, None, :, :].to(DEVICE))\n",
    "encodings_test = model_conv.encoder(test_data[:, None, :, :].to(DEVICE))\n",
    "\n",
    "encodings_train = encodings_train.cpu().detach().numpy()\n",
    "encodings_test = encodings_test.cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:47:05.842140200Z",
     "start_time": "2024-12-19T20:47:05.775523Z"
    }
   },
   "id": "c9829d3be500f8ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1a8841616540564"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc        f1      prec     rec\n10   all  0.984834  0.848218  0.847563  0.8501",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.984834</td>\n      <td>0.848218</td>\n      <td>0.847563</td>\n      <td>0.8501</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:47:10.917168Z",
     "start_time": "2024-12-19T20:47:05.839135400Z"
    }
   },
   "id": "fb3f042735a87a12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc723c7df78d64b"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc        f1      prec     rec\n10   all  0.985479  0.847246  0.848644  0.8501",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.985479</td>\n      <td>0.847246</td>\n      <td>0.848644</td>\n      <td>0.8501</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:47:17.395830600Z",
     "start_time": "2024-12-19T20:47:10.919168400Z"
    }
   },
   "id": "8ab7d2d172443af9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results didn't improve over mlp autoencoder despite better reconstruction loss\n",
    "\n",
    "Best score achieved for logistic regression and mlp autoencoder - above 0.986 auroc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72c0d066773cf6d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Kuzushiji mnist\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ce0395fb3bcfaec"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "dataset_name = \"kuzushiji_mnist\"\n",
    "\n",
    "train_data = kuzushiji_train_data\n",
    "test_data = kuzushiji_test_data\n",
    "\n",
    "train_labels = kuzushiji_train_labels\n",
    "test_labels = kuzushiji_test_labels\n",
    "\n",
    "train_dataset = TensorDataset(train_data)\n",
    "test_dataset = TensorDataset(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:47:17.395830600Z",
     "start_time": "2024-12-19T20:47:17.388060600Z"
    }
   },
   "id": "726913dfd06635f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP AE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b17f9db4c6da064f"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.003274, Test Loss: 0.003357\n",
      "Epoch 10/50, Train Loss: 0.003036, Test Loss: 0.003114\n",
      "Epoch 15/50, Train Loss: 0.002935, Test Loss: 0.002996\n",
      "Epoch 20/50, Train Loss: 0.002880, Test Loss: 0.002941\n",
      "Epoch 25/50, Train Loss: 0.002844, Test Loss: 0.002883\n",
      "Epoch 30/50, Train Loss: 0.002821, Test Loss: 0.002860\n",
      "Epoch 35/50, Train Loss: 0.002802, Test Loss: 0.002840\n",
      "Epoch 40/50, Train Loss: 0.002790, Test Loss: 0.002823\n",
      "Epoch 45/50, Train Loss: 0.002780, Test Loss: 0.002817\n",
      "Epoch 50/50, Train Loss: 0.002771, Test Loss: 0.002799\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(input_dim=input_dim, embedding_dim=embedding_dim).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(model, optimizer, train_dataset, test_dataset, dataset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:48:22.257450900Z",
     "start_time": "2024-12-19T20:47:17.389831Z"
    }
   },
   "id": "d5d99cd40c4a3911"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "encodings_train = model.encoder(train_data.view(-1, 784).to(DEVICE))\n",
    "encodings_test = model.encoder(test_data.view(-1, 784).to(DEVICE))\n",
    "\n",
    "encodings_train = encodings_train.cpu().detach().numpy()\n",
    "encodings_test = encodings_test.cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:48:22.315857700Z",
     "start_time": "2024-12-19T20:48:22.258451200Z"
    }
   },
   "id": "737a135c3275f36e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b08cd4837e4c8ec"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "   label    auroc        f1      prec     rec\n10   all  0.95718  0.740726  0.746162  0.7392",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.95718</td>\n      <td>0.740726</td>\n      <td>0.746162</td>\n      <td>0.7392</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:48:26.846070Z",
     "start_time": "2024-12-19T20:48:22.315857700Z"
    }
   },
   "id": "f9702129777cd919"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14b25d399c380d84"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc        f1     prec     rec\n10   all  0.973758  0.811195  0.81639  0.8116",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.973758</td>\n      <td>0.811195</td>\n      <td>0.81639</td>\n      <td>0.8116</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:48:32.745392600Z",
     "start_time": "2024-12-19T20:48:26.848070300Z"
    }
   },
   "id": "95725435b280b2ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convolution AE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15c61c5d73cde5ff"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.002701, Test Loss: 0.002686\n",
      "Epoch 10/50, Train Loss: 0.002652, Test Loss: 0.002638\n",
      "Epoch 15/50, Train Loss: 0.002635, Test Loss: 0.002624\n",
      "Epoch 20/50, Train Loss: 0.002627, Test Loss: 0.002614\n",
      "Epoch 25/50, Train Loss: 0.002622, Test Loss: 0.002610\n",
      "Epoch 30/50, Train Loss: 0.002619, Test Loss: 0.002611\n",
      "Epoch 35/50, Train Loss: 0.002616, Test Loss: 0.002608\n",
      "Epoch 40/50, Train Loss: 0.002615, Test Loss: 0.002604\n",
      "Epoch 45/50, Train Loss: 0.002613, Test Loss: 0.002603\n",
      "Epoch 50/50, Train Loss: 0.002612, Test Loss: 0.002601\n"
     ]
    }
   ],
   "source": [
    "model_conv = ConvAutoencoder(embedding_dim=embedding_dim).to(DEVICE)\n",
    "optimizer = optim.Adam(model_conv.parameters(), lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    model_conv, optimizer, train_dataset, test_dataset, dataset_name, flatten=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:49:44.297008300Z",
     "start_time": "2024-12-19T20:48:32.745392600Z"
    }
   },
   "id": "dceb58b39e1cd4d"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "model_conv.eval()\n",
    "\n",
    "encodings_train = model_conv.encoder(train_data[:, None, :, :].to(DEVICE))\n",
    "encodings_test = model_conv.encoder(test_data[:, None, :, :].to(DEVICE))\n",
    "\n",
    "encodings_train = encodings_train.cpu().detach().numpy()\n",
    "encodings_test = encodings_test.cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:49:44.353229500Z",
     "start_time": "2024-12-19T20:49:44.285009Z"
    }
   },
   "id": "6e00068e9b8396e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d30b8188bf31fc04"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc        f1      prec    rec\n10   all  0.945362  0.706561  0.713068  0.705",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.945362</td>\n      <td>0.706561</td>\n      <td>0.713068</td>\n      <td>0.705</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:49:48.992181800Z",
     "start_time": "2024-12-19T20:49:44.354229Z"
    }
   },
   "id": "2c2697a2ebb17ccb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "335134470f85be0b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "   label     auroc       f1      prec     rec\n10   all  0.969898  0.79183  0.797107  0.7919",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>auroc</th>\n      <th>f1</th>\n      <th>prec</th>\n      <th>rec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>all</td>\n      <td>0.969898</td>\n      <td>0.79183</td>\n      <td>0.797107</td>\n      <td>0.7919</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf.fit(encodings_train, train_labels)\n",
    "result_df = get_score_df(clf, encodings_test, test_labels)\n",
    "result_df.tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:49:55.024416200Z",
     "start_time": "2024-12-19T20:49:48.983181Z"
    }
   },
   "id": "4da143826dd25b01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convolution based autoencoder achieved better reconstruction error but still didn't give us better representation for classification\n",
    "\n",
    "Best score for kuzushiji mnist - Features from first layer of DBN - above 0.979 auroc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "998a64c9e105eb0e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "97d20ccd2e0a9918"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
