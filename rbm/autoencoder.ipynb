{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Autoencoders\n",
    "\n",
    "## Data\n",
    "\n",
    "### Import and load datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "893e85ce239811db"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, KMNIST\n",
    "\n",
    "mnist = MNIST(\n",
    "    root=\"data/mnist\",\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "mnist_test = MNIST(root=\"data/mnist\", download=True, train=False)\n",
    "\n",
    "fashion = FashionMNIST(\n",
    "    root=\"data/fmnist\",\n",
    "    download=True,\n",
    ")\n",
    "fashion_test = FashionMNIST(root=\"data/fmnist\", download=True, train=False)\n",
    "\n",
    "kuzushiji = KMNIST(\n",
    "    root=\"data/kmnist\",\n",
    "    download=True,\n",
    ")\n",
    "kuzushiji_test = KMNIST(root=\"data/kmnist\", download=True, train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:50:26.402276Z",
     "start_time": "2024-12-19T19:50:26.306944500Z"
    }
   },
   "id": "6146b6b353a14671"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piotr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:66: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\piotr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:76: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "mnist_train_data = mnist.data\n",
    "mnist_train_labels = mnist.train_labels\n",
    "mnist_test_data = mnist_test.data\n",
    "mnist_test_labels = mnist_test.targets\n",
    "\n",
    "fashion_train_data = fashion.train_data\n",
    "fashion_train_labels = fashion.train_labels\n",
    "fashion_test_data = fashion_test.data\n",
    "fashion_test_labels = fashion_test.targets\n",
    "\n",
    "kuzushiji_train_data = kuzushiji.train_data\n",
    "kuzushiji_train_labels = kuzushiji.train_labels\n",
    "kuzushiji_test_data = kuzushiji_test.data\n",
    "kuzushiji_test_labels = kuzushiji_test.targets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:50:26.408770300Z",
     "start_time": "2024-12-19T19:50:26.402276Z"
    }
   },
   "id": "9293b0e6bb8c1092"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalize the image histogram"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "600267ddad7cca1e"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(images):\n",
    "    histograms = np.apply_along_axis(\n",
    "        np.bincount, 1, images.reshape(images.shape[0], -1), minlength=256\n",
    "    )\n",
    "\n",
    "    cdf = histograms.cumsum(axis=1)\n",
    "    cdf_min = cdf[:, 0][\n",
    "        :, None\n",
    "    ]  # Minimum of the CDF (first non-zero element in each row)\n",
    "\n",
    "    # Normalize the CDF for each image\n",
    "    cdf_m = ((cdf - cdf_min) * 255) / (cdf.max(axis=1)[:, None] - cdf_min)\n",
    "\n",
    "    cdf_m = cdf_m.astype(np.uint8)\n",
    "\n",
    "    # Apply normalized CDF to each image\n",
    "    normalized_images = cdf_m[\n",
    "        np.arange(images.shape[0])[:, None, None], images\n",
    "    ]  #  Broadcasting across images and index\n",
    "\n",
    "    return normalized_images\n",
    "\n",
    "\n",
    "mnist_train_data = normalize(mnist_train_data)/265\n",
    "mnist_test_data = normalize(mnist_test_data)/265\n",
    "\n",
    "fashion_train_data = normalize(fashion_train_data)/265\n",
    "fashion_test_data = normalize(fashion_test_data)/265\n",
    "\n",
    "kuzushiji_train_data = normalize(kuzushiji_train_data)/265\n",
    "kuzushiji_test_data = normalize(kuzushiji_test_data)/265"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:50:28.268092900Z",
     "start_time": "2024-12-19T19:50:26.408770300Z"
    }
   },
   "id": "ac7dab5168ba71c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert to torch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e10321a0f458775"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "mnist_train_data = torch.tensor(mnist_train_data,dtype=torch.float32)\n",
    "mnist_test_data = torch.tensor(mnist_test_data,dtype=torch.float32)\n",
    "\n",
    "fashion_train_data = torch.tensor(fashion_train_data,dtype=torch.float32)\n",
    "fashion_test_data = torch.tensor(fashion_test_data,dtype=torch.float32)\n",
    "\n",
    "kuzushiji_train_data = torch.tensor(kuzushiji_train_data,dtype=torch.float32)\n",
    "kuzushiji_test_data = torch.tensor(kuzushiji_test_data,dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:50:28.379131700Z",
     "start_time": "2024-12-19T19:50:28.269092600Z"
    }
   },
   "id": "bfb8f4bd92b23256"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Model\n",
    "\n",
    "### Architecture"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a67a04f36fab956b"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, embedding_dim=196):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:50:28.385119400Z",
     "start_time": "2024-12-19T19:50:28.379131700Z"
    }
   },
   "id": "97dbd5ec53e15c57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the autoencoder class\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 196),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(196, 32 * 7 * 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (32, 7, 7)),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53c0587dd0f98494"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5687fcb73c457f6"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "embedding_dim = 196\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning_rate = 1e-3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:50:28.391645900Z",
     "start_time": "2024-12-19T19:50:28.383315700Z"
    }
   },
   "id": "82ce61f4872a9332"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b382465f8a35f0c"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(mnist_train_data)\n",
    "test_dataset = TensorDataset(mnist_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:50:28.391645900Z",
     "start_time": "2024-12-19T19:50:28.386132800Z"
    }
   },
   "id": "7cb5f1d4f309205"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "209acd78a94ad25e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loop function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe19b5bdf3a10715"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_dataset, test_dataset, dataset_name):\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            images = batch[0]\n",
    "            images = images.view(-1, 784).to(DEVICE)\n",
    "    \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "    \n",
    "        train_loss /= len(train_dataset)\n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                images = batch[0]\n",
    "                images = images.view(-1, 784).to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, images)\n",
    "                test_loss += loss.item()\n",
    "    \n",
    "        test_loss /= len(test_dataset)\n",
    "    \n",
    "        if epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\"\n",
    "            )\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), f\"autoencoder_{dataset_name}.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:50:28.392652900Z",
     "start_time": "2024-12-19T19:50:28.391138500Z"
    }
   },
   "id": "284a91744978fc82"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.002625, Test Loss: 0.001980\n",
      "Epoch 6/50, Train Loss: 0.001605, Test Loss: 0.001611\n",
      "Epoch 11/50, Train Loss: 0.001547, Test Loss: 0.001562\n",
      "Epoch 16/50, Train Loss: 0.001518, Test Loss: 0.001542\n",
      "Epoch 21/50, Train Loss: 0.001498, Test Loss: 0.001521\n",
      "Epoch 26/50, Train Loss: 0.001483, Test Loss: 0.001502\n",
      "Epoch 31/50, Train Loss: 0.001472, Test Loss: 0.001493\n",
      "Epoch 36/50, Train Loss: 0.001462, Test Loss: 0.001479\n",
      "Epoch 41/50, Train Loss: 0.001453, Test Loss: 0.001472\n",
      "Epoch 46/50, Train Loss: 0.001446, Test Loss: 0.001462\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = Autoencoder(input_dim=input_dim, embedding_dim=embedding_dim).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "training_loop(model, optimizer, train_dataset, test_dataset, \"mnist\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:51:47.149621Z",
     "start_time": "2024-12-19T19:50:28.393652500Z"
    }
   },
   "id": "a288bfebde453713"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:51:47.162247700Z",
     "start_time": "2024-12-19T19:51:47.150562800Z"
    }
   },
   "id": "7af9a965401ab2d5"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T19:51:47.162247700Z",
     "start_time": "2024-12-19T19:51:47.152074800Z"
    }
   },
   "id": "ec304972ed55aeb4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
