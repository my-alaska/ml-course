{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d697882-d510-4fc4-a626-5f21ec3aa073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "fashion_train = FashionMNIST(\n",
    "    root=\"data/fmnist\",\n",
    "    download=True,\n",
    ")\n",
    "fashion_test = FashionMNIST(root=\"data/fmnist\", train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0cf7a476-5289-4edb-98d4-94e589b16a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fashion_train.data\n",
    "train_labels = fashion_train.targets\n",
    "\n",
    "test_data = fashion_train.data\n",
    "test_labels = fashion_train.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85e3d511-e957-44bd-80ac-bd7627f38a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b1817c54-73e0-473b-ace9-f139cac55dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images):\n",
    "\n",
    "    histograms = np.apply_along_axis(\n",
    "        np.bincount, 1, images.reshape(images.shape[0], -1), minlength=256\n",
    "    )\n",
    "\n",
    "    cdf = histograms.cumsum(axis=1)\n",
    "    cdf_min = cdf[:, 0][\n",
    "        :, None\n",
    "    ]  # Minimum of the CDF (first non-zero element in each row)\n",
    "\n",
    "    # Normalize the CDF for each image\n",
    "    cdf_m = ((cdf - cdf_min) * 255) / (cdf.max(axis=1)[:, None] - cdf_min).astype(\n",
    "        np.uint8\n",
    "    )\n",
    "\n",
    "    idx = np.arange(images.shape[0])\n",
    "\n",
    "    print(cdf_m.shape)\n",
    "\n",
    "    # Apply normalized CDF to each image\n",
    "    normalized_images = cdf_m[:, images][\n",
    "        idx, idx\n",
    "    ]  # Broadcasting across images and index\n",
    "\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "76b6d02f-ee77-46aa-a02e-d1d157dc3a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9483/1432295053.py:11: RuntimeWarning: divide by zero encountered in divide\n",
      "  cdf_m = ((cdf - cdf_min) * 255) / (cdf.max(axis=1)[:,None] - cdf_min).astype(np.uint8)\n",
      "/tmp/ipykernel_9483/1432295053.py:11: RuntimeWarning: invalid value encountered in divide\n",
      "  cdf_m = ((cdf - cdf_min) * 255) / (cdf.max(axis=1)[:,None] - cdf_min).astype(np.uint8)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 20.5 TiB for an array with shape (60000, 28, 28, 60000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_norm \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[124], line 18\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(cdf_m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Apply normalized CDF to each image\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m normalized_images \u001b[38;5;241m=\u001b[39m \u001b[43mcdf_m\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m[idx,idx] \u001b[38;5;66;03m# Broadcasting across images and index\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m normalized_images\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 20.5 TiB for an array with shape (60000, 28, 28, 60000) and data type float64"
     ]
    }
   ],
   "source": [
    "train_norm = normalize(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ca6e9-c641-444c-996c-c469a9384124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_norm[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "773b2249-1600-4e03-95af-c9b8ad7bd788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28, 28)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d945d0-2411-4554-8fdc-ad0671960644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
